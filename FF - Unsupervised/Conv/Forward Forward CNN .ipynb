{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff01f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.signal import convolve2d\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.functional import F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995322ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 1024\n",
    "learning_rate = 0.03\n",
    "learning_rate_lc = 0.05\n",
    "epochs = 50\n",
    "threshold = 2.0\n",
    "image_shape = (1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST(\"./data/\",download=True, train=True, transform=ToTensor())\n",
    "test_dataset = MNIST(\"./data/\",download=True, train=False, transform=ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True, )\n",
    "test_loader = DataLoader(test_dataset, batch_size=batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d8fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_oh(y):\n",
    "    y = y.numpy().reshape(-1,1)\n",
    "    ohe = OneHotEncoder().fit(np.arange(10).reshape((10,1)))\n",
    "    ohe_y = ohe.transform(y).toarray()\n",
    "    return torch.Tensor(ohe_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ecf9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(x):\n",
    "    x = x.squeeze()\n",
    "    plt.imshow(x, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3090a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The method for generating masks for negative data mentioned by Geoffrey Hinton in the article\n",
    "def mask_gen():\n",
    "    random_iter = np.random.randint(5,10)\n",
    "    random_image = np.random.randint(2, size=image_shape).squeeze().astype(np.float32)\n",
    "    blur_filter = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]]) / 16\n",
    "    for i in range(random_iter):\n",
    "        random_image = convolve2d(random_image, blur_filter, mode='same', boundary='symm')\n",
    "    mask = (random_image > 0.5).astype(np.float32)\n",
    "    return mask\n",
    "\n",
    "# The method for creating masks for negative data that I tried for testing purposes.\n",
    "def mask_gen1():\n",
    "    n = image_1d_shape\n",
    "    arr1 = np.random.normal(loc=0, scale=0.01, size=int(5*n/8))\n",
    "    arr1 = arr1+ abs(0-arr1.min())\n",
    "    arr2 = np.random.normal(loc=1, scale=0.01, size=int(3*n/8))\n",
    "    arr2 = arr2 + abs(1-arr2.max())\n",
    "    arr = np.concatenate([arr1,arr2])\n",
    "    np.random.shuffle(arr)\n",
    "    mask = arr.reshape(image_shape).astype(np.float32)\n",
    "    return mask\n",
    "\n",
    "show_image(mask_gen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f075c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_data_gen(batch):\n",
    "    batch = batch[0]\n",
    "    indexes = torch.randperm(batch.shape[0])\n",
    "    x1 = batch\n",
    "    x2 = batch[indexes]\n",
    "    mask = mask_gen()\n",
    "    merged_x1 = x1*mask\n",
    "    merged_x2 = x2*(1-mask)\n",
    "    hybrid_image = merged_x1+merged_x2\n",
    "    return hybrid_image\n",
    "\n",
    "x = next(iter(train_loader))\n",
    "show_image(negative_data_gen(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(FFConv2d, self).__init__(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.optimizer = Adam(self.parameters(), lr=learning_rate)\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-4)\n",
    "        output = F.conv2d(x_direction, self.weight.cuda(), bias=self.bias.cuda(), stride=self.stride, padding=self.padding) \n",
    "        return F.relu(output)\n",
    "    \n",
    "    def train(self, x_pos, x_neg, epoch_num):\n",
    "        for i in range(epoch_num):\n",
    "            out_pos = self.forward(x_pos).pow(2).mean(1)\n",
    "            out_neg = self.forward(x_neg).pow(2).mean(1)\n",
    "            loss = torch.log(1+ torch.exp(torch.cat([threshold-out_pos,out_neg-threshold]))).mean()\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        return self.forward(x_pos).detach(), self.forward(x_neg).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = FFConv2d(in_channels=1, out_channels=128, kernel_size=10, stride=6)\n",
    "        self.conv2 = FFConv2d(in_channels=128, out_channels=220, kernel_size=3)\n",
    "        self.conv3 = FFConv2d(in_channels=220, out_channels=512, kernel_size=2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def respresentation_vects(self,x):\n",
    "        layers_output = torch.Tensor([]).cuda()\n",
    "        layer1 = self.conv1(x)\n",
    "        layer2 = self.conv2(layer1)\n",
    "        layer3 = self.conv3(layer2)\n",
    "        layers_output = torch.cat([layers_output, layer1.view(-1, np.prod(list(layer1.shape[1:]))),\n",
    "                                                   layer2.view(-1, np.prod(list(layer2.shape[1:]))),\n",
    "                                                   layer3.view(-1, np.prod(list(layer3.shape[1:])))],1)\n",
    "\n",
    "        return layers_output\n",
    "        \n",
    "    def train(self, x_pos, x_neg, epoch_num):\n",
    "        out_pos, out_neg = x_pos, x_neg\n",
    "        out_pos, out_neg = self.conv1.train(out_pos, out_neg,epoch_num)\n",
    "        out_pos, out_neg = self.conv2.train(out_pos, out_neg,epoch_num)\n",
    "        out_pos, out_neg = self.conv3.train(out_pos, out_neg,epoch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c3df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFConvNet()\n",
    "\n",
    "model_train_loop = tqdm_notebook(iter(train_loader),leave=True) \n",
    "batch = None\n",
    "for batch in model_train_loop:\n",
    "    x_pos = batch[0]\n",
    "    x_neg = negative_data_gen(batch)\n",
    "    x_pos, x_neg = x_pos.cuda(), x_neg.cuda()\n",
    "    model.train(x_pos,x_neg,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369a76db",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = batch[0].cuda()\n",
    "rep_vects_shape = model.respresentation_vects(x).detach().shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e7194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassification(nn.Module):\n",
    "    def __init__(self, input_dimension):\n",
    "        super().__init__()\n",
    "        self.epoch_loss = []\n",
    "        self.epoch_acc = []\n",
    "        self.linear = torch.nn.Linear(input_dimension, 10).cuda()\n",
    "        self.optimizer = SGD(self.parameters(), lr=learning_rate_lc)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "    def predict(self,x):\n",
    "        x = x.cuda()\n",
    "        h_activity = model.respresentation_vects(x)\n",
    "        y_h = self.forward(h_activity)\n",
    "        soft_out = self.softmax(y_h)\n",
    "        return soft_out.argmax(1)\n",
    "    \n",
    "    def accuracy_f(self, y_pred, y_true):\n",
    "        batch_size = y_pred.size(0)\n",
    "        _, predicted_labels = y_pred.max(1)\n",
    "        y_pred_onehot = torch.zeros_like(y_pred)\n",
    "        y_pred_onehot.scatter_(1, predicted_labels.view(-1,1), 1)\n",
    "        correct = (y_pred_onehot == y_true).sum().item()\n",
    "        accuracy = correct / (batch_size * y_true.size(1))\n",
    "        return accuracy\n",
    "        \n",
    "        \n",
    "    def train(self, data_loader,epoch_num):\n",
    "        linear_loop = tqdm_notebook(range(epoch_num),total=epoch_num)\n",
    "        for i in linear_loop:\n",
    "            batch_loss = []\n",
    "            batch_accuracy = []\n",
    "            for batch in iter(data_loader):\n",
    "                x,y = batch\n",
    "                x = x.cuda()\n",
    "                y_r = label_to_oh(y).cuda()\n",
    "                h_activity = model.respresentation_vects(x)\n",
    "                y_h = self.forward(h_activity)\n",
    "                accuracy = self.accuracy_f(y_h,y_r)\n",
    "                loss = self.criterion(y_h,y_r)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                batch_loss.append(loss)\n",
    "                batch_accuracy.append(float(accuracy))\n",
    "            self.epoch_acc.append(float(sum(batch_accuracy)/len(batch_accuracy)))\n",
    "            self.epoch_loss.append(float(sum(batch_loss)/len(batch_loss)))\n",
    "            linear_loop.set_description(f\"Epoch [{i+1}/{epoch_num}]: \")\n",
    "            linear_loop.set_postfix(loss=self.epoch_loss[i],accuracy=self.epoch_acc[i])    \n",
    "            \n",
    "    def test(self, data_loader):\n",
    "        batch_loss = []\n",
    "        batch_accuracy = []\n",
    "        test_loss = 0\n",
    "        for batch in iter(data_loader):\n",
    "            x,y = batch\n",
    "            x = x.cuda()\n",
    "            y_r = label_to_oh(y).cuda()\n",
    "            h_activity = model.respresentation_vects(x)\n",
    "            y_h = self.forward(h_activity)\n",
    "            accuracy = self.accuracy_f(y_h,y_r)\n",
    "            loss = self.criterion(y_h,y_r)\n",
    "            batch_loss.append(loss)\n",
    "            batch_accuracy.append(float(accuracy))\n",
    "        test_loss = float(sum(batch_loss)/len(batch_loss))\n",
    "        test_accuracy = float(sum(batch_accuracy)/len(batch_accuracy))\n",
    "        return test_loss,test_accuracy\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a71b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = LinearClassification(rep_vects_shape)\n",
    "linear_model.train(train_loader,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c747fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss,test_acc = linear_model.test(test_loader)\n",
    "print(\"Test Loss: \",test_loss)\n",
    "print(\"Test Accuracy: \",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bedf477",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs+1), linear_model.epoch_acc, 'b-', label='Train Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Train Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs+1), linear_model.epoch_loss, 'r-', label='Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b69426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(test_loader)\n",
    "n = 4\n",
    "fig, ax1 = plt.subplots(1, n)\n",
    "a = 0\n",
    "for i in range(n):\n",
    "    x = next(iterator)[0]\n",
    "    num=int(linear_model.predict(x)[0])\n",
    "    ax1[i].imshow(x[0].squeeze(),cmap=\"gray\")\n",
    "    ax1[i].set_title(str(num))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
